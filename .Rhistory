summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
source('D:/CEU/Web_Scraping/web_scrapping_Yuri/Final_Project/Expedia_Extraction_R.R')
#Load Necessary Packages and Clean the Enviroment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
rm(list=ls())
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=633eb647-3e68-4a76-9ec5-91e060397c41&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=1ed28b8c-c03b-4142-be44-c0862629c19d&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
#final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
#final_df <- dplyr::union(tbf,previous_data)
write.table(tbf, "Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
#final_df <- dplyr::union(tbf,previous_data)
write.table(tbf,  "Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=1ed28b8c-c03b-4142-be44-c0862629c19d&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
#final_df <- dplyr::union(tbf,previous_data)
write.table(tbf,  "Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
#final_df <- dplyr::union(tbf,previous_data)
write.table(tbf,  "Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
#final_df <- dplyr::union(tbf,previous_data)
write.table(tbf,  "Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
#Load Necessary Packages and Clean the Enviroment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
rm(list=ls())
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=cf4b1814-5f95-4785-a03b-406cb9315e66&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
##### Read the file ######
flights_df <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/flights_table.csv")
kable(head(flights_df,10))
source('D:/CEU/Web_Scraping/web_scrapping_Yuri/Final_Project/Expedia_Extraction_R.R')
#Load Necessary Packages and Clean the Enviroment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
rm(list=ls())
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=5d1f31eb-c98b-411c-9cff-9710863293e8&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
#Load Necessary Packages and Clean the Enviroment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
rm(list=ls())
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=5d1f31eb-c98b-411c-9cff-9710863293e8&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
#Load Necessary Packages and Clean the Enviroment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
rm(list=ls())
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=5d1f31eb-c98b-411c-9cff-9710863293e8&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.table("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
#Load Necessary Packages and Clean the Enviroment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
rm(list=ls())
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=5d1f31eb-c98b-411c-9cff-9710863293e8&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.table("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
#Load Necessary Packages and Clean the Enviroment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
rm(list=ls())
SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=e15f405f-472d-4c46-a1cf-a3ae5f934e45&is=1&sp=asc&cz=200&cn=0"
summary_type <- 'Connection'
# Retrieve Flights Summary ------------------------------------------------
#### Doing it to show that we can retrieve also tables from a list instead of unique values
get_summary_flights <- function(SearchString, summary_type = 'AirCompany'){
##### Define the variables and get the JSON ########
df <- list()
tbf = data.frame()
df <- fromJSON(SearchString)
final_df = data.frame()
if(summary_type == 'Connection'){
################## FILTER CONNECTION SUMMARY ######################
previous_data <- read.table("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv")
tbf <- df$content$summary$filters$stopFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Qtd_connections = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byconnection.csv", row.names = FALSE)
return(final_df)
}else{
################################### SUMMARY AIRLINE FILTERS ##################################################
previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv")
tbf <- df$content$summary$filters$airlineFilters
tbf$run_time <- Sys.time()
tbf = subset(tbf, select = -c(filterCategory,formattedReferencePrice,formattedPrice))
tbf <- tbf %>% rename( Number_of_Flights = totalCount,
Min_Price = priceAsDouble,
Air_Line_Company = filterName)
tbf <- separate(data = tbf, into = c("search_date", "search_time"), col = run_time , sep = ' ')
tbf$search_day_period <- with(tbf,  ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
final_df <- dplyr::union(tbf,previous_data)
write.table(final_df , "D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/summary_byaircompany.csv", row.names = FALSE)
return(final_df)
}
}
final_summary <- get_summary_flights(SearchString, summary_type)
#Load Necessary Packages and Clean the Environment
library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
library(purrr)
rm(list=ls())
