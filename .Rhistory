library(rvest)
library(data.table)
library(rvest)
my_url <- 'https://www.economist.com/finance-and-economics/'
get_one_page <- function(my_url) {
t <- read_html(my_url)
boxes <-
t %>%
html_nodes('.teaser')
box_dfs <- lapply(boxes, function(x){
tlist <- list()
tlist[['my_title']] <-
x %>%
html_nodes('.headline-link')%>%
html_text()
my_relative_link <-
x%>%
html_nodes('.headline-link')%>%
html_attr('href')
tlist[['my_link']] <- paste0('https://www.economist.com/', my_relative_link)
tlist[['my_teaser']] <-
x %>%
html_nodes('.teaser__text')%>%
html_text()
#
return(tlist)
})
df <- rbindlist(box_dfs, fill = T)
return(df)
#
}
df <- get_one_page(my_url)
View(df)
rm(list=ls())
rm(list=ls())
library(rvest)
library(data.table)
my_url <- 'https://www.economist.com/finance-and-economics/'
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.teaser')
View(boxes)
View(boxes)
tlist <- list()
boxes
x <- boxes[1]
x
tlist[['my_title']] <-
x %>%
html_nodes('.headline-link')%>%
html_text()
my_relative_link <-
x%>%
html_nodes('.headline-link')%>%
html_attr('href')
tlist[['my_link']] <- paste0('https://www.economist.com/', my_relative_link)
tlist[['my_teaser']] <-
x %>%
html_nodes('.teaser__text')%>%
html_text()
tlist
df <- rbindlist(box_dfs, fill = T)
df <- rbindlist(tlist, fill = T)
rm(list=ls())
my_url <- 'https://www.economist.com/finance-and-economics/'
df <- get_one_page(my_url)
get_one_page <- function(my_url) {
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.teaser')
box_dfs <- lapply(boxes, function(x){
tlist <- list()
tlist[['my_title']] <-
x %>%
html_nodes('.headline-link')%>%
html_text()
my_relative_link <-
x%>%
html_nodes('.headline-link')%>%
html_attr('href')
tlist[['my_link']] <- paste0('https://www.economist.com/', my_relative_link)
tlist[['my_teaser']] <-
x %>%
html_nodes('.teaser__text')%>%
html_text()
#
return(tlist)
})
df <- rbindlist(box_dfs, fill = T)
return(df)
#
}
df <- get_one_page(my_url)
View(df)
get_data_from_economist <- function(number_of_page=5) {
pages <- c('https://www.economist.com/finance-and-economics/', paste0('https://www.economist.com/finance-and-economics/?page=',2:number_of_page))
df <- rbindlist(lapply(pages, get_one_page))
return(df)
}
df <- get_data_from_economist(3)
View(df)
rm(list=ls())
library(data.table)
library(rvest)
rm(list=ls())
searchword <- 'corona'
numberofpages <- 1
my_url_link <- paste0('https://edition.cnn.com/search?q=',
searchword,
'&size=100&page=',
numberofpages)
my_url_link
t <- read_html(my_url_link)
boxes <- t %>%
html_nodes('.cnn-search__result-headline a')
boxes <- t %>%
html_nodes('.cnn-search__result-headline')
View(boxes)
boxes <- t %>%
html_nodes('.cnn-search__result')
my_url_link <- paste0('https://edition.cnn.com/search?q=',
searchword,
'&size=100&page=', numberofpages)
t <- read_html(my_url_link)
my_url_link
boxes <- t %>%
html_nodes('.teaser')
View(t)
my_url_link <- paste0('http://edition.cnn.com/search?q=',
searchword,
'&size=100&page=', numberofpages)
t <- read_html(my_url_link)
boxes <- t %>%
html_nodes('.teaser')
View(boxes)
my_url <- 'https://www.economist.com/finance-and-economics/'
t <- read_html(my_url)
boxes <-
t %>%
html_nodes('.teaser')
View(boxes)
rm(list=ls())
my_url_link <- paste0('http://edition.cnn.com/search?q=',
searchword,
'&size=100&page=', numberofpages)
searchword <- 'corona'
numberofpages <- 1
my_url_link <- paste0('http://edition.cnn.com/search?q=',
searchword,
'&size=100&page=', numberofpages)
t <- read_html(my_url_link)
t <- read_html(my_url_link)
t_list <- list()
t_list[['title']] <- x %>% html_nodes('.cnn-search__result-headline a') %>% html_text()
t_list[['title']] <- my_url_link %>% html_nodes('.cnn-search__result-headline a') %>% html_text()
boxes <- t %>%
html_nodes('.cnn-search__results-list')
View(boxes)
boxes <- t %>%
html_nodes('.cnn-search__result-contents')
boxes <- t %>%
html_nodes('.cnn-search__result-headline')
boxes <- t %>%
html_nodes('.cnn-search__result-body')
boxes <- t %>%
html_nodes('.cnn-search__topic')
rm(list=ls())
searchword <- 'Silva'
numberofpages <- 2
my_url_link <- paste0('https://www.sherdog.com/search.php?q=',
searchword,
'&_siq_page=', numberofpages)
my_url_link
t <- read_html(my_url_link)
View(t)
boxes <- t %>%
html_nodes('.contentTd :nth-child(1)')
View(boxes)
my_url <- 'https://www.economist.com/finance-and-economics/'
t <- read_html(my_url)
boxes <-
t %>%
html_nodes('.teaser')
View(boxes)
t <- read_html(my_url_link)
boxes <- t %>%
html_nodes('.contentTd :nth-child(1)')
View(boxes)
boxes <- t %>%
html_node('.contentTd :nth-child(1)')
t <- read_html(my_url_link)
boxes <- t %>%
html_nodes('.contentTd :nth-child(1)')
my_url_link <- paste0('https://www.sherdog.com/search.php?q=',
searchword,
'&_siq_page=', numberofpages)
rm(list=ls())
searchword <- 'Silva'
numberofpages <- 2
my_url_link <- paste0('https://www.sherdog.com/search.php?q=',
searchword,
'&_siq_page=', numberofpages)
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.shadow')
t <- read_html(my_url)
my_url <- 'https://www.technewsworld.com/perl/search.pl?x=16&y=10&query=big+data'
boxes <- t %>%
html_nodes('.shadow')
t <- read_html(my_url)
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.shadow')
rm(list=ls())
searchword <- 'Corona'
numberofpages <- 2
my_url <- paste0('https://edition.cnn.com/search?q=',
searchword,
'&size=100&page=', numberofpages)
t <- read_html(my_url_link)
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.cnn-search__result--article')
boxes <- t %>%
html_nodes('.cnn-search__result--article') %>% html_text()
my_url <- 'https://www.nytimes.com/search?query=corona'
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.css-1l4w6pd div')
View(boxes)
View(boxes)
my_url <- 'https://www.newsinlevels.com/page/2/?s=corona'
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.title')
rm(list=ls())
searchword <- 'corona'
numberofpages <- 2
for (i in 1:numberofpages){
my_url <- paste0('https://www.newsinlevels.com/page/',
numberofpages, '/?s=',
searchword)
my_url <- paste0('https://www.newsinlevels.com/page/',
numberofpages, '/?s=',
searchword)
my_url <- 'https://www.newsinlevels.com/page/2/?s=corona'
rm(list=ls())
rm(list=ls())
break
break
get_my_url <- function(searchword, numberofpages){
df_total = data.frame()
for (i in 1:numberofpages){
my_url <- paste0('https://www.newsinlevels.com/page/',
numberofpages, '/?s=',
searchword)
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.title') %>%  html_text()
boxes_links <- t %>%
html_nodes('.title a') %>% html_attr('href')
boxes_df <- lapply(boxes, function(x){
trimws(substr(x,
instr(x , '\n', startpos = 2) + 2,
instr(x , ':', startpos = 2) + 2))
t_list <- list()
t_list[['title']] <- trimws(substr(x ,4,instr(x , '\n', startpos = 2) - 1))
t_list[['date']] <-  trimws(substr(x,
instr(x , '\n', startpos = 2) + 2,
instr(x , ':', startpos = 2) + 2))
t_list[['teaser']] <- trimws(substr(x,
instr(x , ':', startpos = 2) + 3,
nchar(x)))
return(data.frame(t_list))
})
df <- rbindlist(boxes_df)
df$link <- boxes_links
df_total <- rbind(df_total,df)
}
return(df_total)
}
news_in_levels_corona <- get_my_url(searchword = 'corona', numberofpages =  5)
library(data.table)
library(rvest)
library(survPen)
library(tidyverse)
news_in_levels_corona <- get_my_url(searchword = 'corona', numberofpages =  5)
news_in_levels_trump <- get_my_url(searchword = 'Trump', numberofpages =  5)
write.csv( news_in_levels_corona,'news_in_levels_corona.csv')
write.csv(news_in_levels_corona,'news_in_levels_Trump.csv')
saveRDS(news_in_levels_corona, file = 'news_in_levels_corona.rds')
saveRDS(news_in_levels_trump, file = 'news_in_levels_trump.rds')
install.packages("prettydoc")
library(prettydoc)
get_my_url <- function(searchword, numberofpages){
df_total = data.frame()
for (i in 1:numberofpages){
my_url <- paste0('https://www.newsinlevels.com/page/',
numberofpages, '/?s=',
searchword)
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.title') %>%  html_text()
boxes_links <- t %>%
html_nodes('.title a') %>% html_attr('href')
boxes_df <- lapply(boxes, function(x){
trimws(substr(x,
instr(x , '\n', startpos = 2) + 2,
instr(x , ':', startpos = 2) + 2))
t_list <- list()
t_list[['title']] <- trimws(substr(x ,4,instr(x , '\n', startpos = 2) - 1))
t_list[['date']] <-  trimws(substr(x,
instr(x , '\n', startpos = 2) + 2,
instr(x , ':', startpos = 2) + 2))
t_list[['teaser']] <- trimws(substr(x,
instr(x , ':', startpos = 2) + 3,
nchar(x)))
return(data.frame(t_list))
})
df <- rbindlist(boxes_df)
df$link <- boxes_links
df_total <- rbind(df_total,df)
}
return(df_total)
}
library(data.table)
library(rvest)
library(survPen)
library(tidyverse)
library(prettydoc)
get_my_url <- function(searchword, numberofpages){
df_total = data.frame()
for (i in 1:numberofpages){
my_url <- paste0('https://www.newsinlevels.com/page/',
numberofpages, '/?s=',
searchword)
t <- read_html(my_url)
boxes <- t %>%
html_nodes('.title') %>%  html_text()
boxes_links <- t %>%
html_nodes('.title a') %>% html_attr('href')
boxes_df <- lapply(boxes, function(x){
trimws(substr(x,
instr(x , '\n', startpos = 2) + 2,
instr(x , ':', startpos = 2) + 2))
t_list <- list()
t_list[['title']] <- trimws(substr(x ,4,instr(x , '\n', startpos = 2) - 1))
t_list[['date']] <-  trimws(substr(x,
instr(x , '\n', startpos = 2) + 2,
instr(x , ':', startpos = 2) + 2))
t_list[['teaser']] <- trimws(substr(x,
instr(x , ':', startpos = 2) + 3,
nchar(x)))
return(data.frame(t_list))
})
df <- rbindlist(boxes_df)
df$link <- boxes_links
df_total <- rbind(df_total,df)
}
return(df_total)
}
