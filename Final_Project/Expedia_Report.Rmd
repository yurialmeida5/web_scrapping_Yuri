---
title: "Web-Scrapping Final Project 2020"
subtitle: "Extract Flight Data from Expedia Website - Get Back to Budapest" 
date: 2020-12-13
author: "Yuri Almeida Cunha"
output:
  prettydoc::html_pretty:
    theme: architect
    highlight: github
---

```{r, echo= FALSE , include = FALSE }

#Load Necessary Packages and Clean the Environment 

library(rvest)
library(jsonlite)
library(data.table)
library(httr)
library(tidyverse)
library(utils)
library(survPen)
library(lubridate)
library(knitr)
library(purrr)


rm(list=ls())


```


# Introduction

On the following project, It was collected flight information from the Brasilia Airport (BSB) to the Rio de Janeiro (GIG/SDU) in order to be able to decide when and what period of the day to buy a specific set of tickets. With that, the project tries verify what is the correlation between the searched flight prices based on the moment of the day and the remaining days until the trip. 


# Steps to Collect the Data 

## Get to the Website and Define your search terms

Go the the website > https://www.expedia.com.br > once you reach the menu flights. Choose the following configuration:  

From: Brasilia (BSB)  
To: Rio de Janeiro (All Airports)
Date: 07/01/2021  
One Way Flight
1 Passanger  

Once your done, you will be redirected to the page that contains the amount of dedicated flights by company that operates the following path and destination. 

## Retrieve the JSON Link

After selecting the search terms and run the command on the website, a list of flight possibilities will pop up. Open the inspector and check the following URL:  

https://www.expedia.com.br/Flight-Search-Paging?c=c475148f-c55d-4539-b37f-db1b8ed1ba20&is=1&sp=asc&cz=200&cn=0

This is the JSON link that contains most of the necessary information regarding the flights. It's important to take the right one. On the page will find 2 of them, the first one is related to the query parameters used for the search and the second one it's the one that contains the flight information.

## Add the URL and define the summary parameter 

On the webscrapping code there are only two parameters and functions.  

### Function

The function is the one that retrieves the entire flight information dataset, where you can visualize the most important information regarding all flights.

### Parameters

The first parameter is the URL, after copying the URL link, you should replace it on the variable SearchString on the code.  

PS: Due to a connection limitation it`s important to refresh (copy and paste) the JSON link every 3 hours, you may get disconnected and the following won't retrieve the necessary information.

```{r , echo = TRUE}

SearchString <- "https://www.expedia.com.br/Flight-Search-Paging?c=e15f405f-472d-4c46-a1cf-a3ae5f934e45&is=1&sp=asc&cz=200&cn=0"


# Retrieve_Full_DataSet ---------------------------------------------------


get_flights_table <- function(SearchString){
  
  df_total = data.frame()
  
  df_fromJson <- fromJSON(SearchString)
  
  NestedList <- df_fromJson$content$legs
  
  previous_data <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/flights_table.csv")
  
  for (i in 1:length(NestedList)){
    
      t_list <- list()
      t_list[['Fare_Code']] <- NestedList[[i]][['naturalKey']]
      t_list[['Price']] <- NestedList[[i]][['price']][['exactPrice']]
      t_list[['Currency']] <- NestedList[[i]][['price']][['currencyCode']]
      t_list[['AirLineCompany']] <- NestedList[[i]][['carrierSummary']][['airlineName']]
      t_list[['Qtd_Connections']] <- NestedList[[i]][['stops']]
      t_list[['Departure_Airport_City']] <- NestedList[[i]][['departureLocation']][['airportCity']]
      t_list[['Departure_Airport_Code']] <- NestedList[[i]][['departureLocation']][['airportCode']]
      t_list[['Arrival_Airport_City']] <- NestedList[[i]][['arrivalLocation']][['airportCity']]
      t_list[['Arrival_Airport_Code']] <- NestedList[[i]][['arrivalLocation']][['airportCode']]
      t_list[['Departure_Date']] <- NestedList[[i]][['departureTime']][['date']]
      t_list[['Departure_Time']] <- NestedList[[i]][['departureTime']][['time']]
      t_list[['Arrival_Date']] <- NestedList[[i]][['arrivalTime']][['date']]
      t_list[['Arrival_Time']] <- NestedList[[i]][['arrivalTime']][['time']]
      t_list[['Duration_Hours']] <- NestedList[[i]][['duration']][['hours']]
      t_list[['Duration_Minutes']] <- NestedList[[i]][['duration']][['minutes']]
      t_list[['run_time']] <- Sys.time()
      
    df <- data.frame(t_list)
    
    df <- separate(data = df, into = c("search_date", "search_time"), col = run_time , sep = ' ')
    
    df$remaining_days <- as.integer( as.Date(as.character(df$Departure_Date), format="%d/%m/%Y") -
                         as.Date(as.character(df$search_date), format="%Y-%m-%d") )
    
    df$search_day_period <- with(df, ifelse(hour(hms(search_time)) >= 5 & hour(hms(search_time)) <=11, "morning",
                                        ifelse(hour(hms(search_time))>11 & hour(hms(search_time))<=17, "afternoon", "night")))
    
    df_total <- rbind(df_total,df)
    
  }
  
  flights_df <- dplyr::union(df_total,previous_data) 
  
  write.csv(flights_df, 'D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/flights_table.csv', row.names = FALSE )
  
  return(flights_df)
  
}
 
flights_df <- get_flights_table(SearchString)


```

# The Datasets

Once you finished running the codes you will end up having the general flights dataset that contains the general information regarding each one of the flights.  

What is important to mention is the the fact that the dataset will have columns that define the precise moment when the information was web scrapped, with the exactly period of the day and the remaining days until the flight departure.  

Please find the flight dataset example bellow: 


```{r, echo = FALSE}

##### Read the file ######

flights_df <- read.csv("D:/CEU/Web_Scraping/web_scrapping_yuri/Final_Project/Datasets/flights_table.csv")

kable(head(flights_df,10))


```


# THE ANALYSIS


After retrieving the dataset, itÂ´s time for the analysis. The possible questions are detailed bellow:   

 Is it better to buy flights during the morning, afternoon or at night? Do the prices change?   
 Is there any correlation between the days missing to the flight and their price?  
 
 
 To analyze the following you can you use the following codes:
 
 
 
```{r, echo = FALSE}

## Analysis by Day Period and Air Company

Price_Analysis_by_Day_Period_and_Aircompany <- flights_df %>%
  group_by(search_day_period, AirLineCompany) %>% 
  summarise(
    mean     = mean(Price),
    median   = median(Price),
    std      = sd(Price),
    iq_range = IQR(Price), 
    min      = min(Price),
    max      = max(Price)
)

kable(Price_Analysis_by_Day_Period_and_Aircompany)

```
 

```{r , echo = FALSE}

Price_Analysis_Remaing_days <- flights_df %>%
  group_by(remaining_days) %>% 
  summarise(
    mean     = mean(Price),
    median   = median(Price),
    std      = sd(Price),
    iq_range = IQR(Price), 
    min      = min(Price),
    max      = max(Price)
  )
  

kable(Price_Analysis_Remaing_days)

```


Now that the summary statistics are done, it's time to generate the possible correlations (remaining_days ~ min(price), remaining_days ~ mean(price) )

```{r , echo= FALSE}

ggplot( data = Price_Analysis_Remaing_days, aes( x = remaining_days , y = min ) ) + 
  geom_point( color='blue') +
  geom_smooth( method = lm , color = 'red' )


ggplot( data = Price_Analysis_Remaing_days, aes( x = remaining_days , y = mean ) ) + 
  geom_point( color='blue') +
  geom_smooth( method = lm , color = 'red' )


```


# Conclusion


There wasn't enough time to retrieve a sufficient amount of data in order to really answer those analytics questions. In order to create the ideas of the graphs, the data was randomly  to show the structure about what's to be evaluated. 
The project is easy to replicate, you can use different dates and locations, and also and will definitely provide enough information in the future to analyze not only the best ticket buying option, but also how do the air companies regulate their price search data.   






